#Metadata Quality Analysis: Tools & Scripts to Check Your Data
*Christina Harlow, University of Tennessee, Knoxville*
*[ShareFest 2015, Nashville Tennessee](http://www.tenn-share.org/sharefestprograms#Full)*

## Abstract

**Note: This was originally proposed to be a 10 minute lightning talk, so forgive me if it doesn't flow well in spots**

Workflows for digital collections metadata can vary greatly dependent on the platform or digital asset management system one is working with. However, there are ways to pull and review metadata for quality analysis work, then use that analysis to better target metadata remediation projects as well as improve indexing of this metadata. This talk will be a quick introduction to some tools and scripts available for pulling and reviewing metadata sets for quality control purposes. Use cases and examples of these tools and scripts in action, in particular for the University of Tennessee Knoxville as well as the Digital Library of Tennessee, will be presented. This short talk should inspire further community effort on documenting and sharing metadata quality analysis and control workflows, as well as possible lead to future workshops in the state.

##Agenda

1. Introduction
    1a. Purpose of this work
    1b. MARC, XML, JSON; RDA, DC, MODS, DPLA MAP
    1b. Other interest in metadata QA
    1c. GUIs to Scripting
2. MARCEdit
    2a. Reports
    2b. RDA conversion
    2c. Field usage
3. OpenRefine
    3a. Flatter data
    3b. Faceting
    3c. Facet-specific export
4. Python Scripting
    4a. UNT Scripts modified - XML
    4b. Pulling/Querying OAI feeds - XML
    4c. Json Objects Review
    4d. Pymarc Scripts for MARC Reports
5. Catmandu
    5a. MARC field value reports
    5b. Fix language - not XML/Json/format or encoding specific
6. Questions

## Contents of this Repository

- Slides
- Links to tools/script libraries
- Sample datasets
- Examples
