#Metadata Quality Analysis
###Tools & Scripts to Check Your Data

*Christina Harlow, University of Tennessee, Knoxville*

*[ShareFest 2015, Nashville Tennessee](http://www.tenn-share.org/sharefestprograms#Full)*

## Abstract

**Note: This was originally proposed to be a 10 minute lightning talk, so forgive me if it doesn't flow well in spots**

Workflows for digital collections metadata can vary greatly dependent on the platform or digital asset management system one is working with. However, there are ways to pull and review metadata for quality analysis work, then use that analysis to better target metadata remediation projects as well as improve indexing of this metadata. This talk will be a quick introduction to some tools and scripts available for pulling and reviewing metadata sets for quality control purposes. Use cases and examples of these tools and scripts in action, in particular for the University of Tennessee Knoxville as well as the Digital Library of Tennessee, will be presented. This short talk should inspire further community effort on documenting and sharing metadata quality analysis and control workflows, as well as possible lead to future workshops in the state.

##Agenda

1. Introduction
    2. Purpose of this work
    3. MARC, XML, JSON; RDA, DC, MODS, DPLA MAP
    4. Other interest in metadata QA
    5. GUIs to Scripting
2. MARCEdit
    3. Reports - Field usage, Validity
    4. RDA conversion
    5. Examples: Ebooks, Visual Materials Reports
3. OpenRefine
    4. Flatter data - DC, some MODS, Tabular, Json
    5. Faceting, Facet-specific export
    6. Example: DLTN Sets Review - Required, Reconciled Fields
4. Python Scripting
    5. UNT Scripts modified - XML
    6. Pulling/Querying OAI feeds - XML
    7. Json Objects Review
    8. Pymarc Scripts for MARC Reports
5. Catmandu
    6. MARC field value reports
    7. Fix language - not XML/Json/format or encoding specific
6. Questions

## Contents of this Repository

- Slides
- Links to tools/script libraries
- Sample datasets
- Examples
